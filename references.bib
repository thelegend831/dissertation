@inproceedings{livescan3d,
	author = {{Kowalski}, M. and {Naruniec}, J. and {Daniluk}, M.},
	booktitle = {2015 International Conference on 3D Vision},
	doi = {10.1109/3DV.2015.43},
	issn = {null},
	keywords = {data acquisition; image reconstruction; image sensors; natural scenes; public domain software; LiveScan3D; 3D data acquisition system; multiple Kinect v2 sensors; free-open source system; live-3D data acquisition; physical configuration; data gathering; object capture; 3D panorama creation; head shape reconstruction; 3D dynamic scene reconstruction; Three-dimensional displays; Sensors; Cameras; Calibration; Servers; Transforms; Computers; Kinect; 3D reconstruction; LiveScan3D; open source},
	month = {Oct},
	pages = {318--325},
	title = {Livescan3D: A Fast and Inexpensive 3D Data Acquisition System for Multiple Kinect v2 Sensors},
	url = {https://ieeexplore.ieee.org/document/7335499},
	urldate = {2020-03-27},
	year = {2015}
}

@inproceedings{holoportation,
	author = {Orts, Sergio and Rhemann, Christoph and Fanello, Sean and Kim, David and Kowdle, Adarsh and Chang, Wayne and Degtyarev, Yury and Davidson, Philip and Khamis, Sameh and Dou, Minsong and Tankovich, Vladimir and Loop, Charles and Cai, Qin and Chou, Philip and Mennicken, Sarah and Valentin, Julien and Kohli, Pushmeet and Pradeep, Vivek and Wang, Shenlong and Izadi, Shahram},
	booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
	doi = {10.1145/2984511.2984517},
	month = {10},
	organization = {Microsoft Research},
	title = {Holoportation: Virtual 3D Teleportation in Real-time},
	url = {https://www.researchgate.net/publication/306544236_Holoportation_Virtual_3D_Teleportation_in_Real-time},
	urldate = {2020-03-27},
	year = {2016}
}

@article{Immersive-telepresence,
	author = {{Fuchs}, H. and {State}, A. and {Bazin}, J.},
	doi = {10.1109/MC.2014.185},
	issn = {1558-0814},
	journal = {Computer},
	keywords = {image reconstruction; three-dimensional displays; virtual reality; immersive 3D telepresence; 3D acquisition; 3D reconstruction; 3D display; Three-dimensional displays; Cameras; Image reconstruction; Real-time systems; Stereo image processing; Glass; Solid modeling; 3D telepresence; 3D acquisition; 3D reconstruction; 3D display; computer vision; graphics; visualization; augmented reality; BeingThere Centre},
	month = {July},
	number = {7},
	pages = {46--52},
	publisher = {IEEE},
	title = {Immersive 3D Telepresence},
	url = {https://ieeexplore.ieee.org/document/6861875/},
	urldate = {2020-03-27},
	volume = {47},
	year = {2014}
}

@article{group-to-group-telepresence,
	author = {{Beck}, S. and {Kunert}, A. and {Kulik}, A. and {Froehlich}, B.},
	doi = {10.1109/TVCG.2013.33},
	issn = {2160-9306},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	keywords = {image colour analysis; image sensors; solid modelling; stereo image processing; virtual reality; immersive group-to-group telepresence; shared virtual 3D world; coupled projection-based multiuser setups; stereoscopic images; local interaction space; color cameras; registered depth cameras; captured 3D information; virtual user representations; virtual city; world-in-miniature metaphor; Calibration; Cameras; Servers; Streaming media; Image reconstruction; Image color analysis; Virtual reality; Multi-user virtual reality; telepresence; 3D capture.; Computer Graphics; Computer Simulation; Group Processes; Humans; Imaging; Three-Dimensional; Models; Biological; Social Behavior; Telecommunications; User-Computer Interface},
	month = {April},
	number = {4},
	pages = {616--625},
	publisher = {IEEE},
	title = {Immersive Group-to-Group Telepresence},
	url = {https://ieeexplore.ieee.org/document/6479190},
	urldate = {2020-03-27},
	volume = {19},
	year = {2013}
}

@online{marvin-minksy,
	author = {Ackerman, Evan and Guizzo, Erico},
	date = {1-2-2016},
	month = feb,
	organization = {International Society for Presence Research},
	title = {Marvin Minsky (1927-2016) and telepresence},
	url = {https://ispr.info/2016/02/01/marvin-minsky-1927-2016-and-telepresence},
	urldate = {2020-03-27},
	year = {2016}
}

@inproceedings{buxton-telepresence,
	address = {Toronto, Ontario, Canada},
	author = {Buxton, William},
	booktitle = {Proceedings of Graphics Interface '92},
	doi = {10.20380/GI1992.15},
	isbn = {0-9695338-1-0},
	issn = {0713-5424},
	location = {Vancouver, British Columbia, Canada},
	numpages = {7},
	pages = {123--129},
	publisher = {Canadian Information Processing Society},
	series = {GI 1992},
	title = {Telepresence: Integrating shared task and person spaces},
	url = {https://www.billbuxton.com/TelepShrdSpce.pdf},
	urldate = {2020-03-27},
	year = {1992}
}

@article{blue-c,
	address = {New York, NY, USA},
	author = {Gross, Markus and W{\"u}rmlin, Stephan and Naef, Martin and Lamboray, Edouard and Spagno, Christian and Kunz, Andreas and Koller-Meier, Esther and Svoboda, Tomas and {Van Gool}, Luc and Lang, Silke and et al.},
	doi = {10.1145/882262.882350},
	issn = {0730-0301},
	issue_date = {July 2003},
	journal = {ACM Trans. Graph.},
	keywords = {3D Video; virtual environments; real-time graphics; graphics hardware; spatially immersive displays},
	month = jul,
	number = {3},
	numpages = {9},
	pages = {819--827},
	publisher = {Association for Computing Machinery},
	title = {Blue-c: A Spatially Immersive Display and 3D Video Portal for Telepresence},
	url = {https://doi.org/10.1145/882262.882350},
	urldate = {2020-03-27},
	volume = {22},
	year = {2003}
}

@article{wim,
	author = {Stoakley, Richard and Conway, Matthew and Pausch, Y},
	booktitle = {CHI},
	doi = {10.1145/223904.223938},
	editor = {Katz, Irvin R. and Mack, Robert L. and Marks, Linn and Rosson, Mary Beth and Nielsen, Jakob},
	isbn = {0-201-84705-1},
	month = {02},
	pages = {265--272},
	publisher = {ACM/Addison-Wesley},
	title = {Virtual Reality on a WIM: Interactive Worlds in Miniature},
	url = {https://doi.org/10.1145/223904.223938},
	urldate = {2020-03-27},
	year = {1970}
}

@article{original-kinect-microsoft,
	author = {Zhang, Zhengyou},
	doi = {10.1109/MMUL.2012.24},
	issn = {1941-0166},
	journal = {IEEE MultiMedia},
	keywords = {Cameras; Three Dimensional Displays; Sensors; Games; Video Recording; Multimedia; Microsoft Kinect; Human-Computer Interaction; Motion Capture; Computer Vision; Engineering; Computer Science},
	language = {eng},
	month = feb,
	number = {2},
	number2 = {2},
	pages = {4--10},
	publisher = {IEEE},
	title = {Microsoft Kinect Sensor and Its Effect},
	url = {https://ieeexplore.ieee.org/document/6190806},
	urldate = {2020-03-27},
	volume = {19},
	year = {2012-02}
}

@inproceedings{new-kinect,
	address = {Gottingen},
	author = {Lachat, E and Macher, H and Landes, T and Grussenmeyer, P},
	issn = {16821750},
	journal = {The International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences},
	keywords = {Visual Arts},
	language = {eng},
	number = {5},
	pages = {93,100},
	publisher = {Copernicus GmbH},
	title = {FIRST EXPERIENCES WITH KINECT V2 SENSOR FOR CLOSE RANGE 3D MODELLING},
	url = {https://www.researchgate.net/publication/274352936_First_experiences_with_kinect_V2_sensor_for_close_range_3D_modelling},
	urldate = {2020-03-27},
	volume = {XL-5/W4},
	year = {2015}
}

@article{greenhouse-kinect,
	author = {Nissimov, Sharon and Goldberger, Jacob and Alchanatis, Victor},
	doi = {10.1016/j.compag.2015.02.001},
	issn = {0168-1699},
	journal = {Computers and Electronics in Agriculture},
	keywords = {Obstacle Detection; Navigation; Kinect Sensor; Rgb-D; Agriculture},
	language = {eng},
	number = {C},
	pages = {104,115},
	publisher = {Elsevier B.V},
	title = {Obstacle detection in a greenhouse environment using the Kinect sensor},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169915000435},
	urldate = {2020-03-27},
	volume = {113},
	year = {2015-04}
}

@article{ar/vr-construction,
	abstract = {Construction is a high hazard industry which involves many factors that are potentially dangerous to workers. Safety has always been advocated by many construction companies, and they have been working hard to make sure their employees are protected from fatalities and injuries. With the advent of Virtual and Augmented Reality (VR/AR), there has been a witnessed trend of capitalizing on sophisticated immersive VR/AR applications to create forgiving environments for visualizing complex workplace situations, building up risk-preventive knowledge and undergoing training. To better understand the state-of-the-art of VR/AR applications in construction safety (VR/AR-CS) and from which to uncover the related issues and propose possible improvements, this paper starts with a review and synthesis of research evidence for several VR/AR prototypes, products and the related training and evaluation paradigms. Predicated upon a wide range of well-acknowledged scholarly journals, this paper comes up with...},
	address = {Amsterdam},
	author = {Li, Xiao and Yi, Wen and Chi, Hung-Lin and Wang, Xiangyu and Chan, Albert},
	doi = {10.1016/j.autcon.2017.11.003},
	issn = {0926-5805},
	journal = {Automation in Construction},
	keywords = {Studies; Augmented Reality; Occupational Safety; Safety Training; Construction Industry; Augmented Reality; Journals; Hard Surfacing; Inspection; Virtual Reality; Occupational Safety; Taxonomy; Hazard Identification; Training},
	language = {eng},
	pages = {150--162},
	publisher = {Elsevier BV},
	title = {A critical review of virtual and augmented reality (VR/AR) applications in construction safety},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S0926580517309962},
	urldate = {2020-03-27},
	volume = {86},
	year = {2018-02-01}
}

@inproceedings{kinectv1/v2-accuracy-precision,
	author = {Wasenm{\"u}ller, Oliver and Stricker, Didier},
	booktitle = {ACCV Workshops (2)},
	doi = {10.1007/978-3-319-54427-4_3},
	editor = {Chen, Chu-Song and Lu, Jiwen and Ma, Kai-Kuang},
	month = {11},
	pages = {34--45},
	publisher = {Springer},
	series = {Lecture Notes in Computer Science},
	title = {Comparison of Kinect V1 and V2 Depth Images in Terms of Accuracy and Precision},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-54427-4\_3},
	urldate = {2020-03-27},
	volume = 10117,
	year = {2016}
}

@inproceedings{remixed-reality,
	address = {New York, NY, USA},
	articleno = {Paper 129},
	author = {Lindlbauer, David and Wilson, Andy D.},
	booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
	doi = {10.1145/3173574.3173703},
	isbn = {9781450356206},
	keywords = {augmented reality; remixed reality; virtual reality},
	location = {Montreal QC, Canada},
	numpages = {13},
	publisher = {Association for Computing Machinery},
	series = {CHI {\rq}18},
	title = {Remixed Reality: Manipulating Space and Time in Augmented Reality},
	url = {https://doi.org/10.1145/3173574.3173703},
	urldate = {2020-03-27},
	year = {2018}
}

@inproceedings{velt,
	author = {Fender, Andreas and M{\"u}ller, J{\"o}rg},
	booktitle = {ISS},
	doi = {10.1145/3279778.3279794},
	editor = {Koike, Hideki and Ratti, Carlo and Takeuchi, Yuichiro and Fukuchi, Kentaro and Scott, Stacey and Plasencia, Diego Mart{\'\i}nez},
	isbn = {978-1-4503-5694-7},
	month = {11},
	pages = {73--83},
	publisher = {ACM},
	title = {Velt: A Framework for Multi RGB-D Camera Systems},
	url = {https://doi.org/10.1145/3279778.3279794},
	urldate = {2020-03-27},
	year = {2018}
}

@inproceedings{roomalive,
	abstract = {RoomAlive is a proof-of-concept prototype that transforms any room into an immersive, augmented entertainment experience. Our system enables new interactive projection mapping experiences that dynamically adapts content to any room. Users can touch, shoot, stomp, dodge and steer projected content that seamlessly co-exists with their existing physical environment. The basic building blocks of RoomAlive are projector-depth camera units, which can be combined through a scalable, distributed framework. The projector-depth camera units are individually autocalibrating, self-localizing, and create a unified model of the room with no user intervention. We investigate the design space of gaming experiences that are possible with RoomAlive and explore methods for dynamically mapping content based on room layout and user position. Finally we showcase four experience prototypes that demonstrate the novel interactive experiences that are possible with RoomAlive and discuss the design challenges of adapting any game to any room.},
	author = {Jones, Brett and Sodhi, Rajinder and Murdock, Michael and Mehra, Ravish and Benko, Hrvoje and Wilson, Andy and Ofek, Eyal and MacIntyre, Blair and Raghuvanshi, Nikunj and Shapira, Lior},
	booktitle = {UIST '14 Proceedings of the 27th annual ACM symposium on User interface software and technology},
	isbn = {978-1-4503-3069-5},
	month = {October},
	pages = {637--644},
	publisher = {ACM},
	title = {RoomAlive: Magical Experiences Enabled by Scalable, Adaptive Projector-Camera Units},
	url = {https://www.microsoft.com/en-us/research/publication/roomalive-magical-experiences-enabled-by-scalable-adaptive-projector-camera-units https://doi.org/10.1145/2642918.2647383},
	urldate = {2020-03-27},
	year = {2014}
}

@article{kinect-specs,
	author = {Jiao, Jichao and Yuan, Libin and Tang, Weihua and Deng, Zhongliang and Wu, Qi},
	doi = {10.3390/ijgi6110349},
	journal = {ISPRS International Journal of Geo-Information},
	month = {11},
	pages = {349},
	title = {A Post-Rectification Approach of Depth Images of Kinect v2 for 3D Reconstruction of Indoor Scenes},
	volume = {6},
	year = {2017}
}

@article{ICP,
	author = {{Besl}, P. J. and {McKay}, N. D.},
	doi = {10.1109/34.121791},
	issn = {1939-3539},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {computational geometry; convergence of numerical methods; iterative methods; optimisation; pattern recognition; picture processing; 3D shape registration; pattern recognition; point set registration; iterative closest point; geometric entity; mean-square distance metric; convergence; geometric model; Solid modeling; Motion estimation; Iterative closest point algorithm; Iterative algorithms; Testing; Inspection; Shape measurement; Iterative methods; Convergence; Quaternions},
	month = {Feb},
	number = {2},
	pages = {239--256},
	title = {A method for registration of 3-D shapes},
	url = {https://ieeexplore.ieee.org/document/121791},
	urldate = {2020-03-27},
	volume = {14},
	year = {1992}
}

@online{ARCore,
	author = {Google},
	date = {1},
	month = mar,
	title = {Google ARCore},
	url = {https://developers.google.com/ar},
	urldate = {2020-03-27},
	year = {2018}
}

@online{arcore-unity,
	author = {Google},
	date = {2018-02-23},
	title = {ARCore Unity SDK},
	url = {https://github.com/google-ar/arcore-unity-sdk},
	urldate = {2020-03-27}
}

@online{arkit,
	author = {Apple},
	date = {2017-06-05},
	title = {ARKit},
	url = {https://developer.apple.com/augmented-reality/arkit/},
	urldate = {2020-03-27}
}

@online{arfoundation,
	author = {Unity},
	date = {2018-05-2},
	title = {AR Foundation},
	url = {https://unity.com/unity/features/arfoundation},
	urldate = {2020-03-27}
}

@article{reality-virtuality-continuum,
	author = {Milgram, Paul and Takemura, Haruo and Utsumi, Akira and Kishino, Fumio},
	doi = {10.1117/12.197321},
	editor = {Das, Hari},
	journal = {Telemanipulator and Telepresence Technologies},
	month = {01},
	organization = {International Society for Optics and Photonics},
	pages = {282 -- 292},
	publisher = {SPIE},
	title = {Augmented reality: A class of displays on the reality-virtuality continuum},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2351/0000/Augmented-reality--a-class-of-displays-on-the-reality/10.1117/12.197321.short},
	urldate = {2020-03-27},
	volume = {2351},
	year = {1994}
}

